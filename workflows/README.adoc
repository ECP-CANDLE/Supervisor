
:toc:

////
You can compile this locally with
$ ../docs/adoc.sh README.adoc
or just view it on GitHub.

For compatibility for the GitHub and asciidoc program,
internal links <<.>> have to be specified with headers [[.]]
////

= Supervisor Workflows

Demonstration workflows for CANDLE.

== Support

Contact wozniak@mcs.anl.gov for any questions about installing or running CANDLE/Supervisor .

== Installation

These are abbreviated instructions for installing the Supervisor.

. Install Python (2.7+ or 3.5+)
. Install R
. Install necessary Python packages
.. TensorFlow
.. Keras
.. ?
. Install necessary R packages
+
----
$ workflows/common/R/install-candle.sh
----
+
. Install http://swift-lang.github.io/swift-t/guide.html#_installation[Swift/T] +
Enable support for the Python and R installed above.
. Clone the CANDLE Benchmarks and Supervisor
+
----
$ git clone https://github.com/ECP-CANDLE/Benchmarks.git
$ git clone https://github.com/ECP-CANDLE/Supervisor.git
----
+
Note that these must be located in the same directory
. Check out the development branches
+
----
$ cd Benchmarks ; git checkout frameworks ; cd -
$ cd Supervisor ; git checkout master     ; cd -
----
. Test a Benchmark
+
----
$ python Benchmarks/Pilot1/P1B3/p1b3_baseline_keras2.py
----
+
. Test a Supervisor run
+
----
$ Supervisor/workflows/nt3_mlrMBO/test/test-1.sh local
----
+
where +local+ indicates the name of your site (see <<structure,Structure>>).

[[structure]]
== Structure

=== Scripts

There are four types of settings scripts in +workflows/common/sh+:

+langs+::
These are settings for the programming language implementations used in Supervisor, such as +PATH+, +PYTHONPATH+, +LD_LIBRARY_PATH+ (often necessary for R), and Swift/T settings.

+langs-app+::
These are settings for the programming language implementations used in Supervisor by Swift/T +app+ functions.  This environment may be different than the overall workflow environment.

+sched+::
These are settings for the system scheduler (e.g., PBS, SLURM, ...).  They are formatted for the http://swift-lang.github.io/swift-t/sites.html#scheduled_systems[Swift/T scheduler settings].

+modules+::
These contain additional modules that must be loaded on certain sites.

See https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/common/sh/README.adoc[the Common Shell Script Readme] for more information.

=== Sites

The site-specific settings for Supervisor are organized into site files.  These are in +workflows/common/sh+ .

Notable sites include:

+local+::
This is a vanilla Linux installation.

Supercomputers::
We have tested settings for +theta+, +cori+, and +titan+.

Other::
Other machines may be listed too, including development machines used by the CANDLE team.  These may be useful as a reference

==== Creating your own site

. Pick an existing site similar to your own site.
. Copy the scripts to contain the new name.
. Edit the scripts to change +PATH+ and so on.
. Launch as described <<launch,below>>.

[[launch]]
=== Launching a run

The typical front-end to a workflow is a +test+ script.  These are stored in the +test/+ directories for each workflow.

The test script accepts the site as an argument.

These scripts do the following:

. Self-identify (set +THIS+ (the directory in which the script is stored), +EMEWS_PROJECT_ROOT+ (the workflow home directory (parent of +THIS+)), etc.)
. Source CFG_SYS and CFG_PRM files
.. CFG_SYS is the configure-system script: it selects the number of processes, walltime, etc.
.. CFG_PRM is the configure-parameters script: it selects algorithm parameters, such as mlrmbo settings +MAX_ITERATIONS+ and +PARAM_SET_FILE+ (which contains further mlrmbo settings), etc.
. Run +workflow.sh+

+workflow.sh+ is the generic shell wrapper script for a given workflow.  It does the following:

. Self-identify
. Obtain the site argument
. Set an +EXPID+ (experiment identifier)
. Process the CFG_SYS and CFG_PRM
. Load the site-specific settings for +modules+, +lang+, and +sched+
.. It does this with shell function +source_site()+ which is a simple error checking wrapper around +source+
. Set up the restart feature
. Construct the +swift-t+ command line
. Invoke +swift-t workflow.swift+

+workflow.swift+ carries out the workflow as an EMEWS exploration.

+app+ functions specified in +workflow.swift+ invoke the Benchmarks.

=== Customizing the workflow settings

The development workflow for the test scripts is as follows.

+test-1.sh+ corresponds to +cfg-sys-1+ and +cfg-prm-1+ .  These "test 1" scripts should not be modified so that developers have a quick, short test to verify that the system works.

To start a new test case, copy +test-1.sh+, for example, +test-copy.sh+.  +test-copy+ can refer to copies of +cfg-sys-1+ and +cfg-prm-1+ .  Modify the QUEUE, PROJECT, and other settings.  If the new test has value to others on the team, push the copied scripts into Git.

== Extending CANDLE

There are multiple ways to extend CANDLE/Supervisor, including adding new optimizers, using different NN models, etc.

=== Changing the Keras model



[[matrix]]
== The Matrix

This is a matrix of workflow capabilities and CANDLE benchmarks.

[options="header"]
|====
| Workflow  | Synth^1^ | AUEN | https://github.com/ECP-CANDLE/Benchmarks/tree/master/Pilot1/P1B1[P1B1] | https://github.com/ECP-CANDLE/Benchmarks/tree/master/Pilot1/P1B2[P1B2] | https://github.com/ECP-CANDLE/Benchmarks/tree/master/Pilot1/P1B3[P1B3] | https://github.com/ECP-CANDLE/Benchmarks/tree/master/Pilot2/P2B1[P2B1] | NT3
| Invoke^2^ | | <<py-keras.swift>> | | | | |
| Random^3^ | | | <<p1b1_random>> | | | |
| Grid^4^
| <<SimpleSweepCommandLine,SimpleSweepCLI>>  +
  <<SimpleSweepPython>> | | <<p1b1_grid>> | | | |
| https://github.com/DEAP/deap[DEAP] |
  <<GA0>> | <<AUEN_DEAP>> | | | | |
| Hyperopt  | | | <<p1b1_hyperopt>> | | | |
| https://github.com/mlr-org/mlrMBO[mlrMBO] | | | <<p1b1_mlrMBO>> | |
                                                  <<p1b3_mlrMBO>> |
                                                  <<p2b1_mlrMBO>> |
                                                  <<nt3_mlrMBO>>
|====

. _Invoke_ means that we can call this one time from Swift
. _Synth_ means some kind of synthetic task: not a real ML
. Random search
. Grid search

== Demonstrations

[[SimpleSweepCommandLine]]
=== SimpleSweepCommandLine

Demonstrates calling Swift parameter sweep over Python command line tasks.

https://github.com/CODARcode/SwiftExamples/tree/master/SimpleSweepCommandLine[CODARCode/SwiftExamples] SimpleSweepCommandLine

*Systems tested:* Local machine, http://swift-lang.github.io/swift-t/sites.html#_beagle[Beagle]

[[SimpleSweepPython]]
=== SimpleSweepPython

Demonstrates calling Swift parameter sweep over Python in-memory tasks.

http://github.com/CODARcode/SwiftExamples[CODARCode/SwiftExamples] SimpleSweepPython

*Systems tested:* Local machine, http://swift-lang.github.io/swift-t/sites.html#_beagle[Beagle]

=== SimpleSweepPyDB (WIP)

Demonstrates calling Swift parameter sweep over Python in-memory tasks plus inserts to Solr database via pysolr.

http://github.com/CODARcode/SwiftExamples[CODARCode/SwiftExamples] SimpleSweepPyDB

*Systems tested:* WIP: Local machine

[[p1b1_grid]]
=== p1b1_grid

Demonstration of P1B1 on a regular grid parameter sweep.

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p1b1_grid for more details.


[[p1b1_random]]
=== p1b1_random

Demonstration of P1B1 on random parameter sweep.

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p1b1_random for more details.

[[AUEN_DEAP]]
=== AUEN_DEAP

This demo runs an AUEN/Theano evolutionary algorithm.

See the https://github.com/CODARcode/SwiftExamples/tree/master/auen[README here].

*Systems tested:* http://swift-lang.github.io/swift-t/sites.html#_beagle[Beagle]

=== Simple Sweep Command Line

Simple parameter sweep that uses a Python command line task.

* https://github.com/CODARcode/SwiftExamples/tree/master/SimpleSweepCommandLine

=== Simple Sweep Python

Simple parameter sweep that uses a Python function task.

* https://github.com/CODARcode/SwiftExamples/tree/master/SimpleSweepPython

[[GA0]]
=== GA0

Genetic algorithm, difficulty zero.  Pure math objective function with DEAP optimization.

https://github.com/emews/EQ-Py/tree/master/examples/ga0

=== Older auen workflow

This is a Beagle parameter sweep over an older AUEN.

* https://github.com/CODARcode/SwiftExamples/tree/master/auen

=== auen41_ff on Cooley

*Contacts:* Wozniak and Balaprakash +
*Source:* +git@github.com:ECP-CANDLE/Supervisor.git+ http://github.com/ECP-CANDLE/Supervisor/tree/master/workflows[+/workflows/auen41_ff+] +
*Systems tested:* http://swift-lang.github.io/swift-t/sites.html#cooley_candle[Cooley]

Add this Swift/T to your +PATH+: +~wozniak/Public/sfw/x86_64/login/swift-t-conda/stc/bin+

[[py-keras.swift]]
=== py-keras.swift

This simply demonstrates that the model can be run from Swift/T +python()+.

We took the Python program https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/auen41_ff/auen41_ff.py[auen41_ff.py] and turned it into a library that can be imported and run from Swift/T.  The new function entry point is +go()+.  The program still works from the command line

https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/auen41_ff/py-keras.swift[py-keras.swift] simply loads the module +auen41_ff+ and runs +go()+.

The +go()+ function accepts the directory containing the +breast.train.csv+ and +breast.test.csv+ files.  These can be obtained on Cooley at +~wozniak/Public/data/CANDLE/auen41_ff+ .

The run script that you launch is https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/auen41_ff/py-keras-cooley.sh[py-keras-cooley.sh] .  The only non-trivial thing here is that we have to set +PYTHONHOME+ for Keras but we cannot let +qsub+ see this variable (or it will fail), so we hide it as +PH+, and send it to Swift via +swift-t -e+.

This obtains settings from https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/auen41_ff/settings.sh[settings.sh], including +QUEUE+, +PROJECT+, etc.

Output goes in numbered directories +out-NNN+.

==== Example transcript

----
$ ./py-keras-cooley.sh ~wozniak/Public/data/CANDLE/auen41_ff
TURBINE-COBALT SCRIPT
...
JOB_ID=...
... # Job runs...
TOTAL_TIME=...
# Job completed
# View output:
$ less out-001/output.txt
----

[[p1b1_hyperopt]]
=== p1b1_hyperopt

The P1B1 hyperopt workflow evaluates a modified version of the P1B1 benchmark autoencoder using hyperparameters provided by a hyperopt instance. The P1B1 code (p1b1_baseline.py) has been modified to expose a functional interface. The neural net remains the same. Currently, hyperopt minimizes the validation loss.

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p1b1_hyperopt for more details.

[[p1b1_mlrMBO]]
=== p1b1_mlrMBO

The P1B1 mlrMBO workflow evaluates a modified version of the P1B1 benchmark autoencoder using hyperparameters provided by a mlrMBO instance. The P1B1 code (p1b1_baseline.py) has been modified to expose a functional interface. The neural net remains the same. Currently, mlrMBO minimizes the validation loss.

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p1b1_mlrMBO for more details.

[[p1b3_mlrMBO]]
=== p1b3_mlrMBO

The P1B3 mlrMBO workflow evaluates the P1B3 benchmark
using hyperparameters provided by a mlrMBO instance. mlrMBO
minimizes the validation loss.

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p1b3_mlrMBO for more details.

*Systems tested:* http://www.nersc.gov/users/computational-systems/cori[Cori]

[[p2b1_mlrMBO]]
=== p2b1_mlrMBO

The P2B1 mlrMBO workflow evaluates the P2B1 benchmark
using hyperparameters provided by a mlrMBO instance. mlrMBO
minimizes the validation loss (???).

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/p2b1_mlrMBO for more details.

*Systems tested:* http://www.nersc.gov/users/computational-systems/cori[Cori]


[[nt3_xmlrMBO]]
=== nt3_mlrMBO

See https://github.com/ECP-CANDLE/Supervisor/tree/master/workflows/nt3_mlrMBO for more details.

== Objective function guide

In CANDLE, *objective functions* are the calls to the machine learning (ML) models.  They are functions that accept some parameter tuple describing how the model will be run, and return some value, such as a loss.  Typical CANDLE workflows optimize the return value in some parameter space using some model exploration algorithm (ME).

This documents how to read existing objective functions and develop new ones.

=== Swift/T leaf functions

Objective functions are implemented as Swift/T leaf functions, which are http://swift-lang.github.io/swift-t/guide.html#leaf_functions[described here].  In short, leaf functions are opaque to Swift.  For the purposes of CANDLE, a leaf function is a command line program or a call to evaluate a string of Python code in-memory.  Normally, Swift/T is free to evaluate leaf functions anywhere in the system (load balancing) in any order (as long as all input data is ready).

=== Command-line programs

A typical command line invocation is here:

https://github.com/ECP-CANDLE/Supervisor/blob/3e53ec93ba5ad79c114a96287f2d280a8e93ad8a/workflows/p3b1_mlrMBO/swift/ai_workflow3.swift#L83[P3B1 mlrMBO: ai_workflow3.swift]
----
(string obj_result) obj(string params, string iter_indiv_id) {
  string outdir = "%s/run_%s" % (turbine_output, iter_indiv_id);
  file out <"%s/out.txt" % outdir>;
  file err <"%s/err.txt" % outdir>;

  (out,err) = run_model(model_script, params, outdir, iter_indiv_id) =>
  string result_file = "%s/result.txt" % outdir;
  obj_result = get_results(result_file);
  printf(obj_result);
}
----

+obj()+ is an objective function that takes parameters and returns a string to Swift.  The input parameters (+params+) are produced by the ME and are encoded as a JSON fragment.  You can simply print them out in Swift (via +printf()+) to see them.  A unique identifier +iter_indiv_id+ is also provided and used to create a unique output directory for +out.txt+ and +err.txt+.  The model is actually executed in +run_model()+, described below.  Then, its results are obtained by +get_results()+, and also logged to +stdout+ (via +printf()+).

https://github.com/ECP-CANDLE/Supervisor/blob/3e53ec93ba5ad79c114a96287f2d280a8e93ad8a/workflows/p3b1_mlrMBO/swift/ai_workflow3.swift#L35[P3B1 mlrMBO: ai_workflow3.swift]
----
app (file out, file err) run_model (file shfile, string params_string, string instance, string run_id)
{
    "bash" shfile params_string emews_root instance FRAMEWORK exp_id run_id benchmark_timeout @stdout=out @stderr=err;
}
----

This is a Swift +app+ function.  Its body is a command line, populated with the input and output arguments.  Thus, it runs +bash+ on a given script with the parameters, as specified in +obj()+.  Some of the variables referenced in the body are Swift global variables.  The special syntax +@stdout+, +@stderr+ capture those streams respectively.

While the model is actually implemented as Python code, a wrapper Bash shell script is actually invoked here (+shfile+ is https://github.com/ECP-CANDLE/Supervisor/blob/master/workflows/p3b1_mlrMBO/scripts/run_model.sh[scripts/run_model.sh]).  This is so +PYTHONPATH+ and other settings can be configured before invoking +python+.  Additional logging and debugging statements can easily be added to this shell script.  Remember that +stdout+ is captured by +out.txt+ (as described above).

More details about +app+ functions in Swift are http://swift-lang.github.io/swift-t/guide.html#app_functions[here].

=== In-memory Python functions

These functions are simpler and more efficient than +app+ functions.  They run the Python-based model in an in-memory Python interpreter bundled with Swift/T.

A typical in-memory Python objective function is here:

https://github.com/ECP-CANDLE/Supervisor/blob/3e53ec93ba5ad79c114a96287f2d280a8e93ad8a/workflows/p3b1_mlrMBO/swift/workflow3.swift#74[P3B1 mlrMBO: workflow3.swift]
----
(string obj_result) obj(string params, string iter_indiv_id) {
  string outdir = "%s/run_%s" % (turbine_output, iter_indiv_id);
  string code = code_template % (outdir, params, exp_id, iter_indiv_id, benchmark_timeout);
  //make_dir(outdir) =>
  obj_result = python_persist(code, "str(validation_loss)");
  printf(obj_result);
}
----

Note that this function implements the same interface as the previous example, and implements the same computation!  However, instead of launching a shell script that invokes the program python, we simply evaluate a string of Python code in a Python interpreter linked to Swift/T.

The string of Python code is in variable +code+.  This string is constructed from a template defined above as:
----
string code_template =
"""
import p3b1_runner
import json, os
outdir = '%s'
if not os.path.exists(outdir):
    os.makedirs(outdir)
hyper_parameter_map = json.loads('%s')
...
validation_loss = p3b1_runner.run(hyper_parameter_map)
""";
----

Note the string conversion specifications (+%s+).  These are processed in Swift by the Python-inspired format operator +code_template % (...)+.  That allows us to paste the +params+ and other values into the string, before passing it to the Swift +python_persist()+ function.  Following the interface of +python_persist()+, the first code string is executed (with no return value), and the second code string returns a value to Swift.  Thus, the return value of the whole thing is +"str(validation_loss)"+, which is passed back to the ME.  (This function is called +python_persist()+ because the Python interpreter is not reset between calls, its state persists.)

More details about Python functions in Swift are http://swift-lang.github.io/swift-t/guide.html#leaf_python[here].

== Works in progress

=== Oversample

Some kind of preliminary test.

https://github.com/CODARcode/SwiftExamples/tree/master/oversample
