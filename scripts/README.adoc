
== HPO Table

Creates a CSV file from a collection of `model.log` files.

=== Data format

Supervisor creates an output directory such as `/path/to/Output/EXP002`.

Inside `EXP002`, there are subdirectories `run_I_J_K` where `I` is the optimizer run, `J` is the optimization iteration number, and `K` is the sample number within that iteration.

Inside each `run_I_J_K`, there is a `model.log` that is the `stdout` of Supervisor's `model_runner.py`.  It contains run metadata, hyperparameters, timing, and output metrics.  When running in Singularity, `stdout` from the model is redirected elsewhere.  In a non-Singularity run, the model output is captured here as well.

Additionally, `stdout` from the workflow on a per-rank basis may be found in `/path/to/Output/EXP002/out/out-\*.txt`.  Any output from `workflow.swift` (e.g., output from Swift/T's `printf()`)is found in these per-rank files.  A summary from DEAP is reported in the 2nd-highest-rank `out-*.txt`.

The output CSV header is:

----
iteration,sample,<HYPERPARAMETERS>,metric,result,walltime
----

for example:

----
iteration,sample,learning_rate,batch_size,metric,result,walltime
----

The output CSV data has the following format for LGBM:

----
iteration,sample,learning_rate,metric,result,walltime
001,0000,0.35935086615047446,0,val_loss,0.009126724756649347,13
001,0001,0.9403987611761238,0,val_loss,0.012431074177045679,10
001,0002,0.26630100118913236,0,val_loss,0.008143043197684443,13
002,0000,0.36600957028357706,0,val_loss,0.008470928185503029,11
002,0001,0.9403987611761238,0,val_loss,0.012431074177045679,9
...
----

=== Usage

If `E` is the experiment directory (`EXP002` above), and `hpo.csv` is the desired output file, run:

----
$ ./hpo_table.py -p learning_rate,batch_size $E $E/hpo.csv
----

to store the CSV in the experiment directory.

See also:

----
$ ./hpo_table.py -h
----

== HPO Grab

Copies HPO outputs into the Hall of Fame

----
$ hpo-grab.sh HOF MODEL SIZE PARAMS D1 D2 DATASET RANK
----

HOF::
The HallOfFame clone

MODEL::
The model name, e.g., `GraphDRP`

SIZE::
The size from the Hall of Fame standard, e.g., `SMALL`

PARAMS::
The HPO params to extract for `hpo.csv`, e.g., `batch_size,learning_rate`

D1::
The Supervisor output directory, e.g.,
`CANDLE_DATA_DIR/output/GraphDRP/EXP039`

D2::
The Singularity output directory, e.g.,
`CANDLE_DATA_DIR/GraphDRP/Output/EXP039`

DATASET::
The dataset name, e.g., `CCLE`

RANK::
The DEAP rank, which is the 2nd highest rank.  E.g. if `PROCS` is 16 then `RANK` is 14.
